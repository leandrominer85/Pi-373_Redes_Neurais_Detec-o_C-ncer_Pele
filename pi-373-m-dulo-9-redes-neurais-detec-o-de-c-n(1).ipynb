{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:15.502536Z",
     "iopub.status.busy": "2020-11-17T14:12:15.500581Z",
     "iopub.status.idle": "2020-11-17T14:12:22.427088Z",
     "shell.execute_reply": "2020-11-17T14:12:22.426344Z"
    },
    "papermill": {
     "duration": 6.951261,
     "end_time": "2020-11-17T14:12:22.427242",
     "exception": false,
     "start_time": "2020-11-17T14:12:15.475981",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, Input\n",
    "from tensorflow.keras.layers import Flatten, MaxPool2D, AvgPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Reshape, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:23.411754Z",
     "iopub.status.busy": "2020-11-17T14:12:23.410331Z",
     "iopub.status.idle": "2020-11-17T14:12:23.414131Z",
     "shell.execute_reply": "2020-11-17T14:12:23.413013Z"
    },
    "papermill": {
     "duration": 0.034792,
     "end_time": "2020-11-17T14:12:23.414315",
     "exception": false,
     "start_time": "2020-11-17T14:12:23.379523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ao chegar aqui, as imagens já precisam estar pré processadas\n",
    "# criar nova pasta similar à train_main, mas os dados de seus subdiretorios possuirao imagens pré processadas\n",
    "\n",
    "def segmentation(path):\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations = 3)\n",
    "    res = cv2.bitwise_and(img,img,mask = sure_bg)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def bgr_CLAHE(img):\n",
    "    \n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    lab_planes = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit = 2.0,tileGridSize = (6, 6))\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab = cv2.merge(lab_planes)\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos dos  csvs:\n",
    "treino_2018 =\"/media/leandro/84EE-B5FB/isic_2018_treino.csv\"\n",
    "treino_2017 =\"/media/leandro/84EE-B5FB/isic_2017_treino.csv\"\n",
    "teste = \"/media/leandro/84EE-B5FB/isic_2017_teste.csv\"\n",
    "validacao = \"/media/leandro/84EE-B5FB/isic_2017_validacao.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:22.494742Z",
     "iopub.status.busy": "2020-11-17T14:12:22.493522Z",
     "iopub.status.idle": "2020-11-17T14:12:22.497190Z",
     "shell.execute_reply": "2020-11-17T14:12:22.496428Z"
    },
    "papermill": {
     "duration": 0.020864,
     "end_time": "2020-11-17T14:12:22.497322",
     "exception": false,
     "start_time": "2020-11-17T14:12:22.476458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------- VALIDAÇÃO (extração e pré processamento)\n",
    "\n",
    "# tratando\n",
    "df_validacao_2017 = pd.read_csv(validacao)\n",
    "\n",
    "df_validacao_2017.drop('seborrheic_keratosis', axis = 1, inplace = True)\n",
    "df_validacao_2017.columns = ['img', 'pos']\n",
    "df_validacao_2017['img'] = df_validacao_2017['img'].apply(lambda x: x + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0001769.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0001852.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0001871.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0003462.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0003539.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                img  pos\n",
       "0  ISIC_0001769.jpg  0.0\n",
       "1  ISIC_0001852.jpg  0.0\n",
       "2  ISIC_0001871.jpg  0.0\n",
       "3  ISIC_0003462.jpg  0.0\n",
       "4  ISIC_0003539.jpg  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validacao_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validacao_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio_val = '/media/leandro/84EE-B5FB/isic_2017_validacao/isic_2017_validacao/'\n",
    "pos = '/media/leandro/84EE-B5FB/validacao_main/pos'\n",
    "neg = '/media/leandro/84EE-B5FB/validacao_main/neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dado que possua o dataframe com as imagens de treino, esta célula filtra imagens por ano, classe e aloca\n",
    "# # dados em um diretorio possuindo dois sub diretorios (um para classe positiva e outro para negativa)\n",
    "\n",
    "# neg_files = df_validacao_2017.loc[df_validacao_2017['pos'] == 0]['img'].tolist() \n",
    "# pos_files = df_validacao_2017.loc[df_validacao_2017['pos'] == 1]['img'].tolist()\n",
    "\n",
    "# pos_files = [i for i in os.listdir(diretorio_val) if i in pos_files]\n",
    "\n",
    "# neg_files = [i for i in os.listdir(diretorio_val) if i in neg_files]\n",
    "\n",
    "# for f in pos_files:\n",
    "#     shutil.copy(diretorio_val + f, pos)\n",
    "    \n",
    "\n",
    "# for f in neg_files:\n",
    "#     shutil.copy(diretorio_val + f, neg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:22.530449Z",
     "iopub.status.busy": "2020-11-17T14:12:22.529630Z",
     "iopub.status.idle": "2020-11-17T14:12:22.533367Z",
     "shell.execute_reply": "2020-11-17T14:12:22.533963Z"
    },
    "papermill": {
     "duration": 0.02355,
     "end_time": "2020-11-17T14:12:22.534161",
     "exception": false,
     "start_time": "2020-11-17T14:12:22.510611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------- TREINO 2017\n",
    "\n",
    "df_treino_2017 = pd.read_csv(treino_2017)\n",
    "\n",
    "# adicionando extensão aos nomes dos arquivos\n",
    "df_treino_2017['image_id'] = df_treino_2017['image_id'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "# criando flag para nevus\n",
    "df_treino_2017['nevus'] = ((df_treino_2017.melanoma == 0) & \n",
    "                           (df_treino_2017.seborrheic_keratosis == 0)).astype(float)\n",
    "\n",
    "df_treino_2017.drop('seborrheic_keratosis', axis = 1, inplace = True)\n",
    "\n",
    "# as imagens precisam ser ou nevus ou melanoma\n",
    "df_treino_2017 = df_treino_2017.loc[(df_treino_2017['melanoma'] == 1) | (df_treino_2017['nevus'] == 1)]\n",
    "\n",
    "# ------- TREINO 2018\n",
    "\n",
    "df_treino_2018 = pd.read_csv(treino_2018)\n",
    "\n",
    "# tratando nomes (adicionando extensões aos nomes) e filtrando series \n",
    "df_treino_2018 = df_treino_2018[['image', 'MEL', 'NV']]\n",
    "df_treino_2018['image'] = df_treino_2018['image'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "# imagens precisam ser ou nevus ou melanoma\n",
    "df_treino_2018 = df_treino_2018.loc[(df_treino_2018['MEL'] == 1) | (df_treino_2018['NV'] == 1)]\n",
    "\n",
    "# ------- BALANCEAMENTO\n",
    "\n",
    "# unificar nomes das series, para eventual concat\n",
    "df_treino_2018.columns = ['img', 'pos', 'neg']\n",
    "df_treino_2017.columns = ['img', 'pos', 'neg']\n",
    "\n",
    "# separando casos positivos e negativos de cada ano\n",
    "pos_2018 = df_treino_2018.loc[df_treino_2018['pos'] == 1]\n",
    "pos_2017 = df_treino_2017.loc[df_treino_2017['pos'] == 1]\n",
    "\n",
    "neg_2018 = df_treino_2018.loc[df_treino_2018['neg'] == 1]\n",
    "neg_2017 = df_treino_2017.loc[df_treino_2017['neg'] == 1]\n",
    "\n",
    "# juntando casos positivos e negativos de todos os anos\n",
    "full_pos = pd.concat([pos_2017, pos_2018], axis = 0)\n",
    "full_neg = pd.concat([neg_2017, neg_2018], axis = 0)\n",
    "\n",
    "# amostrando aleatoriamente, n dados negativos, estes consistirão nas observações negativas (a amostragem\n",
    "# é feita para separar um número de imagens equivalente ao número de imagens positivas que temos à disposição)\n",
    "\n",
    "full_neg = full_neg.sample(n = full_pos.shape[0], random_state = seed)\n",
    "\n",
    "full_pos = full_pos[['img', 'pos']]\n",
    "full_neg = full_neg[['img', 'pos']]\n",
    "\n",
    "filenames = pd.concat([full_pos, full_neg]).reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:22.566015Z",
     "iopub.status.busy": "2020-11-17T14:12:22.565229Z",
     "iopub.status.idle": "2020-11-17T14:12:22.568958Z",
     "shell.execute_reply": "2020-11-17T14:12:22.568356Z"
    },
    "papermill": {
     "duration": 0.022136,
     "end_time": "2020-11-17T14:12:22.569114",
     "exception": false,
     "start_time": "2020-11-17T14:12:22.546978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dado que possua o dataframe com as imagens de treino, esta célula filtra imagens por ano, classe e aloca\n",
    "# # dados em um diretorio possuindo dois sub diretorios (um para classe positiva e outro para negativa)\n",
    "\n",
    "# neg_files = filenames.loc[filenames['pos'] == 0]['img'].tolist() \n",
    "# pos_files = filenames.loc[filenames['pos'] == 1]['img'].tolist()\n",
    "\n",
    "# pos_files17 = [i for i in os.listdir('isic_2017_treino') if i in pos_files]\n",
    "# pos_files18 = [i for i in os.listdir('isic_2018_treino') if i in pos_files]\n",
    "\n",
    "# neg_files17 = [i for i in os.listdir('isic_2017_treino') if i in neg_files]\n",
    "# neg_files18 = [i for i in os.listdir('isic_2018_treino') if i in neg_files]\n",
    "\n",
    "# for f in pos_files17:\n",
    "#     shutil.copy('isic_2017_treino/' + f, 'train_main/pos')\n",
    "    \n",
    "# for f in pos_files18:\n",
    "#     shutil.copy('isic_2018_treino/' + f, 'train_main/pos')\n",
    "\n",
    "# for f in neg_files17:\n",
    "#     shutil.copy('isic_2017_treino/' + f, 'train_main/neg')\n",
    "    \n",
    "# for f in neg_files18:\n",
    "#     shutil.copy('isic_2018_treino/' + f, 'train_main/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:22.600547Z",
     "iopub.status.busy": "2020-11-17T14:12:22.599737Z",
     "iopub.status.idle": "2020-11-17T14:12:22.603310Z",
     "shell.execute_reply": "2020-11-17T14:12:22.602525Z"
    },
    "papermill": {
     "duration": 0.021134,
     "end_time": "2020-11-17T14:12:22.603439",
     "exception": false,
     "start_time": "2020-11-17T14:12:22.582305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_main_pos possui duas pastas 'pos' e 'neg', estas contém, respectivamente, os dados de treino positivos\n",
    "# e negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:22.635989Z",
     "iopub.status.busy": "2020-11-17T14:12:22.635020Z",
     "iopub.status.idle": "2020-11-17T14:12:22.638315Z",
     "shell.execute_reply": "2020-11-17T14:12:22.637579Z"
    },
    "papermill": {
     "duration": 0.021672,
     "end_time": "2020-11-17T14:12:22.638446",
     "exception": false,
     "start_time": "2020-11-17T14:12:22.616774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# escolhendo valores para redimensionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio_pos = \"/media/leandro/84EE-B5FB/train_main/pos/\"\n",
    "diretorio_neg = \"/media/leandro/84EE-B5FB/train_main/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [cv2.imread(f'{diretorio_pos}{i}').shape for i in os.listdir(diretorio_pos)]\n",
    "i = pd.Series([i[0] for i in dims])\n",
    "j = pd.Series([i[1] for i in dims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:23.082016Z",
     "iopub.status.busy": "2020-11-17T14:12:23.063752Z",
     "iopub.status.idle": "2020-11-17T14:12:23.087748Z",
     "shell.execute_reply": "2020-11-17T14:12:23.086991Z"
    },
    "papermill": {
     "duration": 0.048892,
     "end_time": "2020-11-17T14:12:23.087889",
     "exception": false,
     "start_time": "2020-11-17T14:12:23.038997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4499, 6748)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.max(), j.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:23.146350Z",
     "iopub.status.busy": "2020-11-17T14:12:23.145244Z",
     "iopub.status.idle": "2020-11-17T14:12:23.150365Z",
     "shell.execute_reply": "2020-11-17T14:12:23.149597Z"
    },
    "papermill": {
     "duration": 0.047369,
     "end_time": "2020-11-17T14:12:23.150509",
     "exception": false,
     "start_time": "2020-11-17T14:12:23.103140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1859.4009661835748, 2698.723027375201)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.mean(), j.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:23.336972Z",
     "iopub.status.busy": "2020-11-17T14:12:23.331802Z",
     "iopub.status.idle": "2020-11-17T14:12:23.361943Z",
     "shell.execute_reply": "2020-11-17T14:12:23.361164Z"
    },
    "papermill": {
     "duration": 0.195089,
     "end_time": "2020-11-17T14:12:23.362117",
     "exception": false,
     "start_time": "2020-11-17T14:12:23.167028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# me parece melhor opção\n",
    "i.median(), j.median()\n",
    "\n",
    "dimensions = (450, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento de imagens e encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:23.557700Z",
     "iopub.status.busy": "2020-11-17T14:12:23.556516Z",
     "iopub.status.idle": "2020-11-17T14:12:23.561426Z",
     "shell.execute_reply": "2020-11-17T14:12:23.562008Z"
    },
    "papermill": {
     "duration": 0.053923,
     "end_time": "2020-11-17T14:12:23.562196",
     "exception": false,
     "start_time": "2020-11-17T14:12:23.508273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gerador = ImageDataGenerator(\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    data_format = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio_treino = \"/media/leandro/84EE-B5FB/train_main/\"\n",
    "diretorio_teste =\"/media/leandro/84EE-B5FB/isic_2017_teste/\"\n",
    "diretorio_val =\"/media/leandro/84EE-B5FB/validacao_main/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2974 images belonging to 2 classes.\n",
      "Found 150 images belonging to 2 classes.\n",
      "Found 600 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size = (50, 50)\n",
    "batch_size = 100\n",
    "\n",
    "gerador_treino = gerador.flow_from_directory(diretorio_treino, \n",
    "                                             target_size = target_size,\n",
    "                                             batch_size = batch_size)\n",
    "\n",
    "gerador_validacao = gerador.flow_from_directory(diretorio_val, \n",
    "                                                target_size = target_size,\n",
    "                                                batch_size = batch_size)\n",
    "\n",
    "gerador_teste = gerador.flow_from_directory(diretorio_teste, \n",
    "                                            target_size = target_size,\n",
    "                                            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_i, cnn_j, cnn_chnls = 50, 50, 3\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(50, (3, 3), input_shape = (cnn_i, cnn_j, cnn_chnls), activation = 'relu'))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(MaxPool2D((2, 2)))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(AvgPool2D((2, 2)))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(AvgPool2D((2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(Dense(1, activation = 'sigmoid'))\n",
    "        \n",
    "cnn.compile(loss = 'binary_crossentropy', optimizer = RMSprop(learning_rate = 0.001))\n",
    "\n",
    "es = EarlyStopping(monitor = 'loss', patience = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "29/29 [==============================] - 91s 3s/step - loss: 5.1470 - val_loss: 4.2596\n",
      "Epoch 2/1000\n",
      "29/29 [==============================] - 61s 2s/step - loss: 3.5066 - val_loss: 2.9576\n",
      "Epoch 3/1000\n",
      "29/29 [==============================] - 61s 2s/step - loss: 2.5400 - val_loss: 2.1807\n",
      "Epoch 4/1000\n",
      "29/29 [==============================] - 61s 2s/step - loss: 1.9348 - val_loss: 1.7058\n",
      "Epoch 5/1000\n",
      "29/29 [==============================] - 62s 2s/step - loss: 1.5389 - val_loss: 1.3761\n",
      "Epoch 6/1000\n",
      "29/29 [==============================] - 63s 2s/step - loss: 1.2512 - val_loss: 1.1302\n",
      "Epoch 7/1000\n",
      "29/29 [==============================] - 61s 2s/step - loss: 1.0401 - val_loss: 0.9530\n",
      "Epoch 8/1000\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.8911 - val_loss: 0.8326\n",
      "Epoch 9/1000\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.7929 - val_loss: 0.7577\n",
      "Epoch 10/1000\n",
      "29/29 [==============================] - 61s 2s/step - loss: 0.7357 - val_loss: 0.7168\n",
      "Epoch 11/1000\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.7067 - val_loss: 0.6990\n",
      "Epoch 12/1000\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.6958 - val_loss: 0.6938\n",
      "Epoch 13/1000\n",
      "29/29 [==============================] - 59s 2s/step - loss: 0.6934 - val_loss: 0.6933\n",
      "Epoch 14/1000\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.6933 - val_loss: 0.6933\n",
      "Epoch 15/1000\n",
      "29/29 [==============================] - 62s 2s/step - loss: 0.6933 - val_loss: 0.6933\n",
      "Epoch 16/1000\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.6933 - val_loss: 0.6933\n",
      "Epoch 17/1000\n",
      "29/29 [==============================] - 60s 2s/step - loss: 0.6933 - val_loss: 0.6933\n",
      "Epoch 18/1000\n",
      "29/29 [==============================] - 64s 2s/step - loss: 0.6933 - val_loss: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff7c04398b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "cnn.fit(gerador_treino, \n",
    "             epochs = 1000, \n",
    "             validation_data = (gerador_validacao),\n",
    "             steps_per_epoch = gerador_treino.samples//batch_size,\n",
    "             validation_steps = gerador_validacao.samples//batch_size,\n",
    "             callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-17T14:12:22.460918Z",
     "iopub.status.busy": "2020-11-17T14:12:22.460029Z",
     "iopub.status.idle": "2020-11-17T14:12:22.463545Z",
     "shell.execute_reply": "2020-11-17T14:12:22.462684Z"
    },
    "papermill": {
     "duration": 0.023233,
     "end_time": "2020-11-17T14:12:22.463708",
     "exception": false,
     "start_time": "2020-11-17T14:12:22.440475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#REDES (autoencoder e nn)\n",
    "\n",
    "#auto encoder (pré processamento)\n",
    "\n",
    "px_h, px_v, chnls = 50, 50, 3\n",
    "ipt_e = Input(shape = (px_h, px_v, chnls))\n",
    "\n",
    "encoder = Conv2D(4, (3, 3), input_shape = (px_h, px_v, chnls), activation = 'relu', padding = 'same')(ipt_e)\n",
    "encoder = MaxPool2D((5, 5))(encoder)\n",
    "encoder = Conv2D(8, (3, 3), activation = 'relu', padding = 'same')(encoder)\n",
    "encoder = MaxPool2D((2, 2))(encoder)\n",
    "encoder = Conv2D(16, (2, 2), activation = 'relu', padding = 'same')(encoder)\n",
    "encoder = Flatten()(encoder)\n",
    "encoder = Dense(32, name = 'gargalo')(encoder)\n",
    "\n",
    "decoder = Dense(400)(encoder)\n",
    "decoder = Reshape(target_shape = (5, 5, 16))(decoder)\n",
    "decoder = Conv2D(8, (2, 2), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(4, (3, 3), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = UpSampling2D((5, 5))(decoder)\n",
    "decoder = Conv2D(4, (3, 3), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = Conv2D(3, (3, 3), activation = 'sigmoid', padding = 'same')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs = ipt_e, outputs = decoder, name = 'autoencoder')\n",
    "autoencoder.compile(loss = 'mean_squared_error')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 50, 50, 4)         112       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 10, 10, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 10, 10, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 5, 5, 16)          528       \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "gargalo (Dense)              (None, 32)                12832     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 400)               13200     \n",
      "_________________________________________________________________\n",
      "reshape_28 (Reshape)         (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 5, 5, 8)           520       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 10, 10, 4)         292       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_37 (UpSampling (None, 50, 50, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_192 (Conv2D)          (None, 50, 50, 4)         148       \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 50, 50, 3)         111       \n",
      "=================================================================\n",
      "Total params: 28,039\n",
      "Trainable params: 28,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-124-d1aa546b96a3>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [100,2] vs. [100,50,50,3]\n\t [[node mean_squared_error/SquaredDifference (defined at <ipython-input-121-09a51d7f21b2>:3) ]] [Op:__inference_train_function_26059]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-d1aa546b96a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m autoencoder.fit_generator(gerador_treino, \n\u001b[0m\u001b[1;32m      4\u001b[0m              \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgerador_validacao\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \"\"\"\n\u001b[1;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [100,2] vs. [100,50,50,3]\n\t [[node mean_squared_error/SquaredDifference (defined at <ipython-input-121-09a51d7f21b2>:3) ]] [Op:__inference_train_function_26059]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "autoencoder.fit_generator(gerador_treino, \n",
    "             epochs = 1000, \n",
    "             validation_data = (gerador_validacao),\n",
    "             steps_per_epoch = gerador_treino.samples//batch_size,\n",
    "             validation_steps = gerador_validacao.samples//batch_size,\n",
    "             callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', patience = 2)\n",
    "\n",
    "autoencoder.fit(x_treino, x_treino,\n",
    "                batch_size = 512,\n",
    "                epochs = 20,\n",
    "                validation_data = (x_valid, x_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 13.364852,
   "end_time": "2020-11-17T14:12:23.689502",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-17T14:12:10.324650",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
