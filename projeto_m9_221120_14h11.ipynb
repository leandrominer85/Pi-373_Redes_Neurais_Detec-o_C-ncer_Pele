{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score , roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, Input\n",
    "from tensorflow.keras.layers import Flatten, MaxPool2D, AvgPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Reshape, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento, balanceamento e split de treino e teste de descritivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos dos  csvs:\n",
    "treino_2018 =\"/media/leandro/84EE-B5FB/isic_2018_treino.csv\"\n",
    "treino_2017 =\"/media/leandro/84EE-B5FB/isic_2017_treino.csv\"\n",
    "teste = \"/media/leandro/84EE-B5FB/isic_2017_teste.csv\"\n",
    "validacao = \"/media/leandro/84EE-B5FB/isic_2017_validacao.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primeiramente, abrimos os descritivos dos dados de treino, a fim de analisar o balanceamento dos dados;\n",
    "# julgamos válido ajustar a rede a um conjunto de dados balanceado, assim, evitando enviesar a rede\n",
    "\n",
    "df_treino_2017 = pd.read_csv(treino_2017)\n",
    "df_treino_2018 = pd.read_csv(treino_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  melanoma  seborrheic_keratosis\n",
       "0  ISIC_0000000       0.0                   0.0\n",
       "1  ISIC_0000001       0.0                   0.0\n",
       "2  ISIC_0000002       1.0                   0.0\n",
       "3  ISIC_0000003       0.0                   0.0\n",
       "4  ISIC_0000004       1.0                   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analisando descritivo de treino de 2017\n",
    "df_treino_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- TREINO 2017\n",
    "\n",
    "df_treino_2017['image_id'] = df_treino_2017['image_id'].apply(lambda x: x + '.jpg')\n",
    "df_treino_2017['nevus'] = ((df_treino_2017['melanoma'] == 0) & \n",
    "                           (df_treino_2017['seborrheic_keratosis'] == 0)).astype(float)\n",
    "df_treino_2017.drop('seborrheic_keratosis', axis = 1, inplace = True)\n",
    "df_treino_2017 = df_treino_2017.loc[(df_treino_2017['melanoma'] == 1) | (df_treino_2017['nevus'] == 1)]\n",
    "\n",
    "# nesta célula, adicionamos extensões aos nomes dos arquivos, para que estes correspondam exatamente aos nomes\n",
    "# que de fato seriam usados para acessar as imagens, por código, em seguida, precisávamos saber quais imagens\n",
    "# eram casos de 'nevus', como esta flag não existe, inferimos que casos que não fossem 'melanoma', nem \n",
    "# 'seborrheic_keratosis' seriam 'nevus', à partir disso, criamos uma terceira flag, eliminamos a flag\n",
    "# 'seborrheic_keratosis', que não nos convinha, por fim, mantivemos no dataframe, apenas as imagens\n",
    "# que representassem ou casos de 'nevus' ou 'melanoma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>nevus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_id  melanoma  nevus\n",
       "0  ISIC_0000000.jpg       0.0    1.0\n",
       "1  ISIC_0000001.jpg       0.0    1.0\n",
       "2  ISIC_0000002.jpg       1.0    0.0\n",
       "3  ISIC_0000003.jpg       0.0    1.0\n",
       "4  ISIC_0000004.jpg       1.0    0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AKIEC</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0024306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0024307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0024308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0024309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
       "0  ISIC_0024306  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "1  ISIC_0024307  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "2  ISIC_0024308  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "3  ISIC_0024309  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "4  ISIC_0024310  1.0  0.0  0.0    0.0  0.0  0.0   0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partimos para o descritivo de treino de 2018\n",
    "\n",
    "df_treino_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- TREINO 2018\n",
    "\n",
    "df_treino_2018['image'] = df_treino_2018['image'].apply(lambda x: x + '.jpg')\n",
    "df_treino_2018 = df_treino_2018.loc[(df_treino_2018['MEL'] == 1) | (df_treino_2018['NV'] == 1)]\n",
    "df_treino_2018 = df_treino_2018[['image', 'MEL', 'NV']]\n",
    "# nesta célula, apenas adicinamos as extensões aos nomes dos arquivos, filtramos imagens que representassem \n",
    "# casos de 'nevus' ou 'melanoma', por meio das flags 'NEV' e 'ML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0024306.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0024307.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0024308.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0024309.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024310.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image  MEL   NV\n",
       "0  ISIC_0024306.jpg  0.0  1.0\n",
       "1  ISIC_0024307.jpg  0.0  1.0\n",
       "2  ISIC_0024308.jpg  0.0  1.0\n",
       "3  ISIC_0024309.jpg  0.0  1.0\n",
       "4  ISIC_0024310.jpg  1.0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui, unificamos os nomes das series dos descritivos, para que possam ser concatenados\n",
    "df_treino_2018.columns = ['img', 'pos', 'neg']\n",
    "df_treino_2017.columns = ['img', 'pos', 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como podemos ver abaixo, as bases estão desbalanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.785796\n",
       "1.0    0.214204\n",
       "Name: pos, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_2017['pos'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.857636\n",
       "1.0    0.142364\n",
       "Name: pos, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_2018['pos'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1487\n",
       "1.0    1487\n",
       "Name: pos, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nesta célula, juntamos as duas bases, como o intuito de obter um conjunto balanceado de dados\n",
    "\n",
    "# separando casos positivos e negativos de cada ano\n",
    "pos_2018 = df_treino_2018.loc[df_treino_2018['pos'] == 1]\n",
    "pos_2017 = df_treino_2017.loc[df_treino_2017['pos'] == 1]\n",
    "\n",
    "neg_2018 = df_treino_2018.loc[df_treino_2018['neg'] == 1]\n",
    "neg_2017 = df_treino_2017.loc[df_treino_2017['neg'] == 1]\n",
    "\n",
    "# juntando casos positivos e negativos de todos os anos\n",
    "full_pos = pd.concat([pos_2017, pos_2018], axis = 0)\n",
    "full_neg = pd.concat([neg_2017, neg_2018], axis = 0)\n",
    "\n",
    "# amostrando aleatoriamente, n dados negativos, estes consistirão nas observações negativas (a amostragem\n",
    "# é feita para separar um número de imagens equivalente ao número de imagens positivas que temos à disposição)\n",
    "full_neg = full_neg.sample(n = full_pos.shape[0], random_state = seed)\n",
    "\n",
    "full_pos = full_pos[['img', 'pos', 'neg']]\n",
    "full_neg = full_neg[['img', 'pos', 'neg']]\n",
    "\n",
    "filenames = pd.concat([full_pos, full_neg]).reset_index().drop('index', axis = 1)\n",
    "\n",
    "filenames['pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com base no conjunto balanceado, obtemos splits de treino e teste\n",
    "df_treino, df_teste = train_test_split(filenames, test_size = 0.2, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisamos aqui, o descritivo de validação\n",
    "\n",
    "df_valid = pd.read_csv(validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>melanoma</th>\n",
       "      <th>seborrheic_keratosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0001769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0001852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0001871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0003462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0003539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  melanoma  seborrheic_keratosis\n",
       "0  ISIC_0001769       0.0                   0.0\n",
       "1  ISIC_0001852       0.0                   0.0\n",
       "2  ISIC_0001871       0.0                   0.0\n",
       "3  ISIC_0003462       0.0                   0.0\n",
       "4  ISIC_0003539       0.0                   0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['image_id'] = df_valid['image_id'].apply(lambda x: x + '.jpg')\n",
    "df_valid['nevus'] = ((df_valid['melanoma'] == 0) & \n",
    "                           (df_valid['seborrheic_keratosis'] == 0)).astype(float)\n",
    "df_valid.drop('seborrheic_keratosis', axis = 1, inplace = True)\n",
    "df_valid = df_valid.loc[(df_valid['melanoma'] == 1) | (df_valid['nevus'] == 1)]\n",
    "\n",
    "df_valid.columns = ['img', 'pos', 'neg']\n",
    "# para o tratamento do descritivo de validação, foi necessário adicionar extensões e criar a flag 'nevus', \n",
    "# de forma similar ao tratamento do descritivo de 2017, além disso, filtramos por apenas casos de \n",
    "# 'melanoma' ou 'nevus', também foram aplicados os mesmos nomes para as series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0001769.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0001852.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0001871.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0003462.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0003539.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                img  pos  neg\n",
       "0  ISIC_0001769.jpg  0.0  1.0\n",
       "1  ISIC_0001852.jpg  0.0  1.0\n",
       "2  ISIC_0001871.jpg  0.0  1.0\n",
       "3  ISIC_0003462.jpg  0.0  1.0\n",
       "4  ISIC_0003539.jpg  0.0  1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.722222\n",
       "1.0    0.277778\n",
       "Name: pos, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# como podemos observar, a base de validação está desbalanceada\n",
    "\n",
    "df_valid['pos'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para balanceá-la, elminaremos casos negativos o suficiente para que o número resultante se equipare \n",
    "# ao número de casos positivos\n",
    "\n",
    "df_valid_pos = df_valid.loc[df_valid['pos'] == 1]\n",
    "df_valid_neg = df_valid.loc[df_valid['neg'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 78)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_valid_pos), len(df_valid_neg)\n",
    "\n",
    "# amostraremos 30 valores aleatórios dentre os casos negativos, e estes serão concatenados ao conjunto de\n",
    "# casos positivos, o conjunto resultante consistirá no descritivo de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_neg = df_valid_neg.sample(30, random_state = seed)\n",
    "df_valid = pd.concat([df_valid_pos, df_valid_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: pos, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid['pos'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descritivo de teste (cujas predições devemos entregar)\n",
    "\n",
    "df_pred = pd.read_csv(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0012086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0012095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0012134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0012136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id\n",
       "0  ISIC_0012086\n",
       "1  ISIC_0012092\n",
       "2  ISIC_0012095\n",
       "3  ISIC_0012134\n",
       "4  ISIC_0012136"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['image_id'] = df_pred['image_id'].apply(lambda x: x + '.jpg')\n",
    "df_pred.columns = ['img']\n",
    "\n",
    "# para o tratamento do descritivo de teste, aplicamos extensões e unificamos nome da series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0012086.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0012092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0012095.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0012134.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0012136.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                img\n",
       "0  ISIC_0012086.jpg\n",
       "1  ISIC_0012092.jpg\n",
       "2  ISIC_0012095.jpg\n",
       "3  ISIC_0012134.jpg\n",
       "4  ISIC_0012136.jpg"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ao final do processo, possuímos df_treino, df_teste, df_valid, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = df_treino.reset_index()\n",
    "df_valid = df_valid.reset_index()\n",
    "df_treino.drop('index', axis = 1, inplace = True)\n",
    "df_valid.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# farei o pré processamento das imagens conforme estiver alimentando o ajuste da rede, este será realizado em \n",
    "# batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisão dos dados de treino em batches\n",
    "\n",
    "n_batches = 5\n",
    "data = df_treino\n",
    "batch_list = []\n",
    "\n",
    "resto = data.shape[0] % n_batches\n",
    "step = data.shape[0] // n_batches\n",
    "count = 0\n",
    "lower_idx = 0\n",
    "\n",
    "for n in range(n_batches):\n",
    "    \n",
    "    upper_idx = lower_idx + step \n",
    "    \n",
    "    exec(f'batch_{count} = data.iloc[{lower_idx}:{upper_idx}]')\n",
    "    exec(f'batch_list.append(batch_{count})')\n",
    "    \n",
    "    count += 1\n",
    "    lower_idx += step\n",
    "    \n",
    "# somando resto ao último batch\n",
    "batch_list[-1] = pd.concat([batch_list[-1], df_treino[-4:]])\n",
    "\n",
    "# agora temos a lista 'batch_list', esta possui cinco dataframes, cada um deles, contendo uma porção de \n",
    "# 'df_treino', carregaremos cada batch e ajustaremos a rede a cada um deles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio_treino = \"/media/leandro/84EE-B5FB/isic_treino_selecionadas/\"\n",
    "diretorio_teste =\"/media/leandro/84EE-B5FB/isic_2017_teste/\"\n",
    "diretorio_val =\"/media/leandro/84EE-B5FB/isic_2017_validacao/isic_2017_validacao/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ao carregarmos cada um dos batches, pré processaremos e faremos 'data augmentation', através de:\n",
    "\n",
    "# carregamento\n",
    "def get_images_n_labels(dataframe, path = diretorio_treino, \n",
    "                        series_name = 'img', label_name = 'pos', i = 50, j = 50):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for n in range(dataframe.shape[0]):\n",
    "        \n",
    "        img = cv2.imread(path + dataframe[series_name].iloc[n])\n",
    "        img = cv2.resize(img, (i, j))\n",
    "        x.append(img)\n",
    "        y.append(dataframe[label_name].iloc[n])\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# pré processamento\n",
    "\n",
    "def segmentation(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations = 3)\n",
    "    res = cv2.bitwise_and(img,img,mask = sure_bg)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def bgr_CLAHE(img):\n",
    "    \n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    lab_planes = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit = 2.0,tileGridSize = (6, 6))\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab = cv2.merge(lab_planes)\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def img_preproc(img):\n",
    "    \n",
    "    img = bgr_CLAHE(segmentation(img))\n",
    "    img = img / 255\n",
    "\n",
    "    \n",
    "    return img\n",
    "\n",
    "# augmentation\n",
    "\n",
    "def zoom(img, original_dim = [50, 50], h_slice = [5, 45], v_slice = [5, 45]):\n",
    "\n",
    "    img = img[v_slice[0] : v_slice[1], h_slice[0] : h_slice[1]]\n",
    "    img = cv2.resize(img, (original_dim[0], original_dim[1]))\n",
    "    \n",
    "    return img \n",
    "\n",
    "# horizontal shift\n",
    "def h_shift(image, original_dim = [50, 50], shift = 5):\n",
    "    \n",
    "    T_x = shift\n",
    "    T_y = 0\n",
    "    \n",
    "    M = np.array([[1, 0, T_x], [0, 1, T_y]], dtype = 'float32')\n",
    "    img_transladada = cv2.warpAffine(image, M, (original_dim[0], original_dim[1]))\n",
    "    img = img_transladada[0 : original_dim[0], shift : original_dim[1]]\n",
    "    img = cv2.resize(img, (original_dim[0], original_dim[1]))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# vertical shift\n",
    "def v_shift(image, original_dim = [50, 50], shift = 5):\n",
    "    \n",
    "    T_x = 0\n",
    "    T_y = shift\n",
    "    \n",
    "    M = np.array([[1, 0, T_x], [0, 1, T_y]], dtype = 'float32')\n",
    "    img_transladada = cv2.warpAffine(image, M, (original_dim[0], original_dim[1]))\n",
    "    img = img_transladada[shift : original_dim[0], 0 : original_dim[1]]\n",
    "    img = cv2.resize(img, (original_dim[0], original_dim[1]))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def rotation_90(img):\n",
    "\n",
    "    rows, cols, chnls = img.shape\n",
    "    M = cv2.getRotationMatrix2D(((cols - 1) / 2.0, (rows - 1) / 2.0), 90, 1)\n",
    "    img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def data_augmentation(x, y):\n",
    "    \n",
    "    augmentation_imgs = []\n",
    "    augmentation_labels = []\n",
    "\n",
    "    for n in range(len(x)):\n",
    "\n",
    "        image = x[n]\n",
    "        classe = y[n]\n",
    "        augment = randint(0, 2) # booleano (33.3% de chance de aplicar augmentation)\n",
    "\n",
    "        if augment == 1:\n",
    "            process = randint(0, 5) # seleção aleatória do processo de augmentation\n",
    "\n",
    "            if process == 0:\n",
    "                image = cv2.flip(image, 0)\n",
    "                augmentation_imgs.append(image) # horizontal flip\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 1:\n",
    "                image = zoom(image)\n",
    "                augmentation_imgs.append(image) # zoom 0.2\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 2:\n",
    "                image = h_shift(image)\n",
    "                augmentation_imgs.append(image) # horizontal shift\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 3:\n",
    "                image = v_shift(image)\n",
    "                augmentation_imgs.append(image) # vertical shift\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 4:\n",
    "                image = rotation_90(image)\n",
    "                augmentation_imgs.append(image) # rotaton 90°\n",
    "                augmentation_labels.append(classe)\n",
    "                \n",
    "    return augmentation_imgs, augmentation_labels\n",
    "\n",
    "# consolidando os processos acima em um função\n",
    "def single_batch_prep(batch_df, width = 50, height = 50):\n",
    "    \n",
    "    x, y = get_images_n_labels(batch_df)\n",
    "\n",
    "    # pré processamento de imagens\n",
    "    x = [img_preproc(i) for i in x]\n",
    "\n",
    "    # data augmentation\n",
    "    augmentation_imgs, augmentation_labels = data_augmentation(x, y)\n",
    "    \n",
    "    return np.array(x + augmentation_imgs), np.array(list(y) + augmentation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px_h, px_v, chnls = 50, 50, 3\n",
    "ipt_e = Input(shape = (px_h, px_v, chnls))\n",
    "\n",
    "encoder = Conv2D(4, (3, 3), input_shape = (px_h, px_v, chnls), activation = 'relu', padding = 'same')(ipt_e)\n",
    "encoder = MaxPool2D((5, 5))(encoder)\n",
    "encoder = Conv2D(8, (3, 3), activation = 'relu', padding = 'same')(encoder)\n",
    "encoder = MaxPool2D((2, 2))(encoder)\n",
    "encoder = Conv2D(16, (2, 2), activation = 'relu', padding = 'same')(encoder)\n",
    "encoder = Flatten()(encoder)\n",
    "encoder = Dense(32, name = 'gargalo')(encoder)\n",
    "\n",
    "decoder = Dense(400)(encoder)\n",
    "decoder = Reshape(target_shape = (5, 5, 16))(decoder)\n",
    "decoder = Conv2D(8, (2, 2), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = UpSampling2D((2, 2))(decoder)\n",
    "decoder = Conv2D(4, (3, 3), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = UpSampling2D((5, 5))(decoder)\n",
    "decoder = Conv2D(4, (3, 3), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = Conv2D(3, (3, 3), activation = 'sigmoid', padding = 'same')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs = ipt_e, outputs = decoder, name = 'autoencoder')\n",
    "autoencoder.compile(loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(batch_0, open('batch_0.pkl', 'wb'))\n",
    "pickle.dump(batch_1, open('batch_1.pkl', 'wb'))\n",
    "pickle.dump(batch_2, open('batch_2.pkl', 'wb'))\n",
    "pickle.dump(batch_3, open('batch_3.pkl', 'wb'))\n",
    "pickle.dump(batch_4, open('batch_4.pkl', 'wb'))\n",
    "\n",
    "autoencoder.save('ae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = get_images_n_labels(df_valid, path = diretorio_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar batch para teste\n",
    "x_0, y_0 = single_batch_prep(batch_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhendo dimensões para resize\n",
    "\n",
    "# dims = [cv2.imread(f'treino_full_non_preproc/{i}').shape \n",
    "#         for i in os.listdir('treino_full_non_preproc') if '.jpg' in i and i in df_treino['img'].tolist()]\n",
    "# i = pd.Series([i[0] for i in dims])\n",
    "# j = pd.Series([i[1] for i in dims])\n",
    "# i.median(), j.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neste notebook, são 5 batches ('batch_0' - 'batch_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no ajuste de um batch, devemos carregar o df descritivo do batch, os dados de validação, o ae, \n",
    "# fazer o ajuste, salvar o ae\n",
    "\n",
    "autoencoder = load_model('ae.h5')\n",
    "batch = pickle.load(open('batch_0.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 23427.5938\n",
      "Epoch 2/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 23437.7480\n",
      "Epoch 3/2000\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 23431.0293\n",
      "Epoch 4/2000\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 23427.9023\n",
      "Epoch 5/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0264 - val_loss: 23440.7793\n",
      "Epoch 6/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 23423.7871\n",
      "Epoch 7/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 23433.1641\n",
      "Epoch 8/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 23431.2246\n",
      "Epoch 9/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 23407.4336\n",
      "Epoch 10/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 23432.2539\n",
      "Epoch 11/2000\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 23442.5645\n",
      "Epoch 12/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 23400.6250\n",
      "Epoch 13/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 23413.0840\n",
      "Epoch 14/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 23382.0254\n",
      "Epoch 15/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 23419.0371\n",
      "Epoch 16/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 23380.6777\n",
      "Epoch 17/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 23414.3184\n",
      "Epoch 18/2000\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 23405.2715\n",
      "Epoch 19/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 23430.2090\n",
      "Epoch 20/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 23390.1797\n",
      "Epoch 21/2000\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 23368.8379\n",
      "Epoch 22/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 23423.6367\n",
      "Epoch 23/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 23395.6055\n",
      "Epoch 24/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 23417.9395\n",
      "Epoch 25/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 23413.7871\n",
      "Epoch 26/2000\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 23399.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05a6b525b0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ajustando encoder ao primeiro batch\n",
    "%timeit\n",
    "autoencoder.fit(x_0, x_0, batch_size = 10, epochs = 2000, validation_data = (x_valid, x_valid), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_cod = autoencoder.predict(x_0)\n",
    "x_valid_cod = autoencoder.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((603, 50, 50, 3), (60, 50, 50, 3))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treino_cod.shape, x_valid_cod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0524154190>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgfUlEQVR4nO2deXTc1ZXnv7dKKpWkUqkkWZLl3Xi3WQwYMJidsIQwQDokDUl3yDTTJHMyZ0h3MoEkc5JJ95w56e4Zkk6nkzQd0vF0cyCQ9ARCJ6RZTIAQDN7wvuHdlrXvUmmrN3+obOn+btmSbalc9vt+zvGxvj+9V7+nqrr1q3t/994nzjkQQs5/Qmd7AYSQ7EBjJ8QTaOyEeAKNnRBPoLET4gk0dkI84YyMXUTuEJEdIrJbRB4br0URQsYfOd377CISBrATwK0ADgF4D8ADzrmtJ5oTkrALhcIjHyPDGH2sIFKgdDSgAaAwGlXaSZ4ZEyssVHr73m0nWiYh5yzOOTjnrGEBsFYxdq4EsNs5twcAROQZAPcAOLGxh8KIF00+rsN5dk3xiDbcC2bMVXruzNlmzsXzFyk9GCk1Y66+6GKlr/3jq060TELOWXqTvSf83Zl8jZ8K4OAIfSh9jBCSg5zJlX1MiMjDAB4GgJCERxlNCJkozsTYDwOYPkJPSx9TOOeeAPAEAOSFIy6E4RhBpq/xiXi50rOmVCldXTHFzIkW6TkFJZPMmIrqyeYYIT5xJl/j3wMwT0Rmi0gEwP0AXhifZRFCxpvTvrI75wZE5L8A+A2AMIAfO+e2jNvKCCHjyhn57M65XwH41TithRAygTCDjhBPmPBo/EgkJMiPDn++lBeVmTFVFRVKR6JxpWOxEjMnGtP35qdNq7bnlsgprZWQ8w1e2QnxBBo7IZ5AYyfEE7Lrs0MQxrDvHI/FzZiK0kqlqyq1nlShE2gA4KLpFyi9ubbZjCkpsPnyhPgEr+yEeAKNnRBPoLET4glZ9dlDEkJhpOi4jhQUmzHVVfo+e1mxvq++7JKLzJyjzf1K52VoXjGlOP+U1krI+Qav7IR4Ao2dEE+gsRPiCTR2QjwhywE6QXF0uDtsdSJhxhQX6C6wJbGY0j3dKTMnkq/nFMb6zZiW5MCpLJWQ8w5e2QnxBBo7IZ5AYyfEE7Lrs4dCKCoa9q+jxTapJlakd3xZOFdvCjF7su0c29KndfhAtxnzu427TmWphJx38MpOiCfQ2AnxBBo7IZ5AYyfEE7LcXTaMgsLhjjGFxbbrTLhAJ9Hs2d+k9KxpRQhyuKlW6VDcBv4+//nrTmmthJxv8MpOiCfQ2AnxBBo7IZ6QVZ89LCGURIaTavLynRkTieikmr4BvcT6zhYzZ3CwV+m2lo4zWSYh5yW8shPiCTR2QjyBxk6IJ2TXZ88LIZ4Yvk8eKyw0Y+IxfY988bwZSjc26PvuADCpUO/ietef3XEmyyTkvIRXdkI8gcZOiCfQ2AnxhFGNXUR+LCL1IrJ5xLFyEXlZRHal/y+b2GUSQs6UsQTofgLgewD+74hjjwF41Tn3LRF5LK0fHf2hBKHw8JbNsWjUjHDQQbvmjjal+/vDZk6zPUQICTDqld059waA4Ibn9wBYmf55JYB7x3dZhJDx5nR99mrn3LG60qMAqk80UEQeFpE1IrKmty95mqcjhJwpZxygc845ADbJffj3TzjnljnnlhVE7Nd2Qkh2ON2kmjoRqXHO1YpIDYD6sUwKhQSR6PDWycVFcTOmuEQXwhw42qh0uMgm4gy2dI3l9IR4zele2V8A8GD65wcBPD8+yyGETBRjufX2NIDfA1ggIodE5CEA3wJwq4jsAvChtCaE5DCjfo13zj1wgl/dMs5rIYRMIDIUX8sOoVDIFUQLRh9ICDktepO9SKVSkul3TJclxBNo7IR4Ao2dEE+gsRPiCTR2QjyBxk6IJ9DYCfEEGjshnkBjJ8QTaOyEeAKNnRBPoLET4gk0dkI8gcZOiCfQ2AnxBBo7IZ5AYyfEE7K6ZTMZP1wqdbaXcBwJ8ZpxLsBXiRBPoLET4gk0dkI8Ied89n/8xk+ULijU3WiP1LWbOR0dg0oPhHrMmKbAoZTTc5KpfARJlFYofd+lc5R+a+sRM+fr3/m4OXam5JJ/nong+ujD5yZ8VQjxBBo7IZ5AYyfEE3LOZw9FtO9cWFykdL9rMXPWHdin9ECv9dk/uvxCpV95Z5PSFVOnmzl3zJ2k9KrNO5VeMPcCM2c8CPrAv3pqixnT3NOv9PsH95kxW97frvSh+galr5lVbuZs7NDnrt21Vek//eT9Zk51sX6eOvp7lf6zr37IzCHZh1d2QjyBxk6IJ9DYCfEEGjshnpBzAbriYp1Es2mXTlwpKIqYOaUxPadjMGnG/OLl3yr9H26/UemGRpusc7ChTun8sP59f58ORJ0uoyXNNHV0mWMSLVR6XvkkM+bi225Q+qXfvq10fYc975TogNKhWfOVXrPrsJlTU9Cn9K0rFiv99A/fN3Me+Nwl5hiZWHhlJ8QTaOyEeMKoxi4i00VklYhsFZEtIvJI+ni5iLwsIrvS/5dN/HIJIafLWHz2AQBfdM6tE5ESAGtF5GUAnwHwqnPuWyLyGIDHADx6pgsKBRzj/EB9SmVFiZkTLUko3dVuffbKKZOVfmt7rdKxPPu5Fy3VuqNNJ/QUzdGFMRNFfbdNEipo1zGGpYsWmjFvb9mt9J6j9Up/crld/+O/fEPpFVesUPpwe6eZEwkVK/3Kmv1Kz51h4wkk+4x6ZXfO1Trn1qV/7gCwDcBUAPcAWJkethLAvRO0RkLIOHBKPruIzAJwKYDVAKqdc8cuj0cBVI/v0ggh48mYb72JSAzAzwF8wTnXLiLHf+eccyLiTjDvYQAPD4kzWish5AwY05VdRPIxZOhPOef+NX24TkRq0r+vAVCfaa5z7gnn3DLn3DKhtRNy1hj1yi5Dl/AnAWxzzj0+4lcvAHgQwLfS/z8/LityeklVVTrIv/eI/Uwp6NOBs6O1e82YVPUMpWdW68+5STF7M2Htvn1Kl+TrtTVnSHb5+f/+d6U/9qXbzJhT5ZK5M82xxrompfsH+82YgZYDStdM11V63/7FajPnozffrvSehlalb11qk2HeP6iDnTWTdWQznq8TdQDgn/9OV/KVl0bNmI98OjsBUF8Yy9f4FQD+GMAmEdmQPvZVDBn5syLyEID9AD4xISskhIwLoxq7c+4tnNjbvmV8l0MImSiYQUeIJ+RcIUy8RBe6FAYKPvqd/XwKJ3USzcHGRjNmdlWl0k0tOlunudMmi1y0eJ7SRQHXc9MO3cUFALoHM96UOCOKJGyOTa7Uf8+/v7vRjHniJ88oXR3Rz+2CC68xc958X/9NW7etUbqy5A/NnAVTpyldWqxfs74M3WZnJGJKL55vu+aQ8YVXdkI8gcZOiCfQ2AnxhJzz2WNF+h7twYO6WUIsbG8MREq0/5eKJcyYD7p1g4V5+bpxQ16RnbOwTN97/7tf6SKR+269zsz5/XrdqOEzn/me0g/dfZOZU16qz1PfouMHLW02BtET0v53ge3pgaJEQukll12ldG/tPjupS3/+f+oOnSfQ1WXvmZeH9T3yD/bo12xGTZWZk4zpx1mz4ZBdCxlXeGUnxBNo7IR4Ao2dEE+gsRPiCTkXoJOITkqpnqyDO82trWZOpEknyFw+d5YZ09uk59V36k4vi2viZs57m7cpPX+eLsxorreBs7IaXXCT167Pu3WrfkwAkDwdoJs9S3fVCQbwAGBPgy7+6U72mTGXL7lc6dVvva70zgZdwAIAt8+ZpfSzq3TgbGalDbbli34bJaEDdp+9/Xozp769W+m+AbtlNhlfeGUnxBNo7IR4Ao2dEE/IOZ+9t1c3YWhp0751fp7e/QUAagO+Z7jTNpVIBno77Go+qvSlC2ebOYVR/Vn44fl6W+fGDLvIfHXFIqWfWqsbaVROrjFzFk+dqvTbe/XaoqFWM2f5Ih0/OHzkqBkjUZ1pc7RZN7yYW2mbYhzo0kUsRQicu1s/BgDsr9PPf7xUxxxee3etmVMRSJ7a2t5sxoy2U85YkAxFOL7CZ4IQT6CxE+IJNHZCPEGcG/9mCyciFAq5gqj1uUfyylOv6gMpff9191Hrm765YbvSPZ0tZkzDAe1rTp+t/eSCsL3Pe/MifU/5d9tblW7q0RoABvfsULovPKh0b5ndueX+G29UOlSin6Nllyyx5wm8bO1ddkfZZ17ShTsf7DiodIHYoqLaJt3Qc3ejvs8e7bGFMNfecKPSVXGdFzCzMmHmzAgWHlUWmTG79un1/sF1Fyu95aiNmfz6bb1TbV+Pzj+ouGCWmfPdv/64OXau0pvsRSqVythGjld2QjyBxk6IJ9DYCfEEGjshnpBzSTU7a3XQ5YJK3YUmJDaQNrVMbxlc195hxkxaOF/plkDgJgG7LfJLG3XHlc2HdeDvsim2I+qS669QeusmvX3xhzN0qqlt1MG1pXGdcPLaFrvDzYUzdUfXVN+gGRNJ6WMPP6Db/P/LC7pzLAC4Vl3ck+d0rOcT937MzOlJ6uSXjsBze6TNJjmtWr9J6SmTp5ox00v08/CDJ59Wuq7YbgVdFghu1rbr53Zyhk69vsArOyGeQGMnxBNo7IR4Qs757EhqH6ujV/vjbc224UK8XPtuRf3WL3tz0walC4p14se8uJ2z+YjeBfXBiy5U+h/fCCQAAVhSs1zpBYt0M4vtuz8wc+6+QXepPRTYuWXdK++aObMDO6XuO2CTjfKc9tnXbd6jdGWZ/ayfPf1KpV96tVXpvnabyDIlnlBaEhVKr95od6tpbKxT+mirLYS569P3K11boauZJidt7kh+4GWcHig8qii3TUqCBTfna/HM+flXEUIMNHZCPIHGTognZNVnn1ozHY989mvHdSSvxIwpiGinazBQdyH5tmBiRlz7YVsa7X32o03aR6wS3RRxco1t6rh9r44P9F2qG1N88robzJyOwM4z8ajOE1hXb33T1HZd8FFTqddy9zVXmzndTdp3roza9V9zzwKlX3p7vdJzSqz/ujXQOOO//eEDSj/71ntmTmWpfi7vv0IXrDz90stmTnGxvh/+wKVLzZhv/s1f6PNUVSt93bUrzJxJU3RTj9++p3elvegO+1z6Aq/shHgCjZ0QT6CxE+IJoxq7iERF5F0ReV9EtojIN9PHZ4vIahHZLSI/FZEM+4gSQnKFsQToegHc7JzrFJF8AG+JyK8B/DmAbzvnnhGRHwJ4CMAPTvZAg4MptI3o/FqdKDZjonk6QDd7qk6Y0aGgIdradEAuKrabSiiukyuaA0kc//CS7YB6yxKdYNJTrwN2b+xvMHOmz7hA6e0b3lH6ikv1Li0AUBbRySH79uuAXWy+DUo+8J/12v7HY8+bMa9vWqf0osm6O+4ra20hTCqpX5OVe15R+p4Vy8ycz92m/6ZfrNadg0rCtktscYEOKL72zioz5rYb7lK6K9Dtt67dFi8l63QhT3mFDgJ/5W/+3szxhVGv7G6IYxuG56f/OQA3A/hZ+vhKAPdOxAIJIePDmHx2EQmLyAYA9QBeBvABgFbn3LFL6CEAtkZxaO7DIrJGRNZ09dhSR0JIdhiTsTvnBp1zSwFMA3AlANs18cRzn3DOLXPOLSsutF/bCSHZ4ZSSapxzrSKyCsDVABIikpe+uk8DcPjks4He/n7sHdEd1oWsBz6jRn9BaGrUvnVVtW0YkRdotVoXsz7ugqqE0psP6OSXvJAuLAGAtYe1j76nVz/Gf7xGN6oAgHd26kKXL/7Rp5Vu77LxhMG4/hDsbk8q3TMw+mdyc7LNHKso091x21v0c9nQoXdSBYDl82cpvXVrq9Kfu8fuyPq/nntJ6WSbLlgJNsAAgEMH9PM0f850M+Zwn/67y0K6SOqKZTb+sXXXTqXX7tLFPwVRf+PIY4nGV4pIIv1zIYBbAWwDsArAfelhDwKwESJCSM4wlit7DYCVIhLG0IfDs865F0VkK4BnROR/AlgP4MkJXCch5AwZ1didcxsBXJrh+B4M+e+EkHMAZtAR4glZrXobHEyho6XzuE5NSpoxvQOdSifCOqnmUKPdMri3V1eADQzYLa1mBrqX1ga2OC6aNcvMaQ90LJlapoOD7++3Mcke6C2Pu4t0klBeyK7tX17+ndJ/dKdOJpmTGP1l+u53Pm2OnU7HlUnFf6n05RfpwNnT7+gqMgBoatVdd/cd0cHPfQ22i05fUo/ZsaffjAlv1h16auYvVfpIna0gXHGNTvqJH9Rru+p6XQkIAOvXfN8cOx/hlZ0QT6CxE+IJNHZCPCGrPrsIEM4b/nyJl9qMut7AziYdnbrIpabCJtW0BHaJaWq2abmNeTrppDymkyva+m3iR02+Tvq5fJEuctmwbbeZ8/XP646o33hKd2kpLdWdawDgr//0k0pv2qm72i5crDvkTCTXL9Kxjf/6iQ8p/c1n3jRzKip1B5l3NryudGVlpZlzYMdqpQci9m+MlSWUzgvpgpqebrs197TA9tCzanQhzMY9R8wcX+CVnRBPoLET4gk0dkI8Ies+e/4I93rd3gNmTFVcNzUom6qLOXp77L35/MBupfNmzzBj2nv1fd0rll+j9I56e//+7bWbla5u1PfVF1Za/3v/Qd3FtqZK+6uxqC3See432g92YR1PmFSoO7FOJPU9Onbx9s56padU6t1eAOCDXXqX2URNoIFHhsYUNYGCp6N19WbML7/2WaUHivW532mxTTEe/6dnlb45cN891GX9fF/glZ0QT6CxE+IJNHZCPIHGTognZDVA5xzQPzAcTJsStZ1qWjt1QswHBw8pXVliEzRmTNXHImEb0BpwOkB3pE2fpztD8cwtV12iz5PQAbkpYTtnS6CzzvzZuqvtzqO6+ykAJMO6WCYW2Gr5zW06ADaRlAaKZ/YFOuiWRO1z2z2oX8eBpE6EunTFTWZOw2HdQXdJpS1q+e6/6S2xv/DIf1J6Bmx3nj+5+059nm4dxLtsqanWxq/t7lTnJbyyE+IJNHZCPIHGTognZNdnTw2iv2fYnyvOz1B8ktCFC4PQY/r6bVJNV1J3bA1n2DamKKYftzpP+57JpO5cCgCL58xWuqVWd5vtj9uOtPHA5+e6nbq76VVLLzJzHvrstXbBp8jpNKrIxLIlOiGmtFzHKX79lt05RyI6xlBVoRuOpBr1cwAAl8ycpnRzb7UZ8+hDdyv95npdxHLLEtuRtq5V+/EXlOnnpS9itzcYr+cu1/HjrySE0NgJ8QUaOyGekFWfHXBwqeH73cle6yfvrdN+cWVC+3/FRfY+b36evt+dnx82YxJRfSwa1r5oX8DPBIBEXDv/xVHtwy+I291FfrNbF3SUxnXxhmTYheV0mCg/s7ddr6+2W8dDrrnENpn4y3/4J6VXXK47jHfGFps5/YEYyd4jtkDl+y/oRpyPPqx9+M2H7HP5J186efzDF/88E/7+5YR4Bo2dEE+gsRPiCTR2QjwhqwG6VCqF7u7hpJjuDAE653SwLZ7QO6zki/18ygvp4FtXhm42iRKdAHPFbTZoZNaSsp1QzgbZDCrlFeig4+RK3QH4xTfeNnOunKsTYtavX6/0wWYbfLvxwqVKL6qxXYMrpk9W+nvP64SeG5bOMXOC+ByQC8JnghBPoLET4gk0dkI8Ibu7uKYcukb47O2t1pdriWkf/chRnfxSEbe7yPTv04UWVZU1ZozLP/VkFh/9vU179il9UaH2ixu6dNELALTW6dhLT0i/rWZP0clIAPD7fbopyU0LZpkxS+fpedv3691g1x3RjTUAP1+zscJnhhBPoLET4gljNnYRCYvIehF5Ma1ni8hqEdktIj8VEZsoTgjJGU7FZ38EwDYA8bT+KwDfds49IyI/BPAQgB+c7AFSqUF0dw83emzt7jBjKgM7t6QG+5WuqLI7khw6pH238knWrywrzNDRghim1OiCoMYm3SDzpkttIcyRUp3n0Pjme0pvb7G7vVyxcKHS11+coVimU7/2ra3tSi+IxxHkvz/6c6X31+v32PQye016/4DemWjFZZcrHYYtrCou1LGlhiN6J6DqctvYZMlC3Tijr8O+TwdSPYFz61yP2z6jd7g5FcZ0ZReRaQA+AuBHaS0Abgbws/SQlQDuPe1VEEImnLF+jf8OgC8Dxz9mKgC0OueO1T8eAmD7/QAQkYdFZI2IrBkcGMg0hBCSBUY1dhG5C0C9c842HxsDzrknnHPLnHPLwnlZLp8nhBxnLNa3AsDdInIngCiGfPa/BZAQkbz01X0agMMneQxCyFlmVGN3zn0FwFcAQERuBPAl59ynROQ5APcBeAbAgwCeH/2xgL7B4a/yPRkKYXr79LHBQIBu63a7O0pFqQ6GZCpgSSbHp0PM+c60Cr1l9vrtu5SORKwr1omE0lVLdICroF4nwwDAXZfrjjLTZ9tOse9s2aH07TdepXRrq90RpqRdJ2pNSujA7MadW82c5qQOlFWU6G5ITc32vbOntVXp6kCwcFetDUrGAp16C2B3FIqk9LHJk+y24KfLmdxnfxTAn4vIbgz58E+Oz5IIIRPBKTnRzrnXAbye/nkPgCtPNp4Qkjswg44QT8hueNylMNg/nDSTSvaZId2BpJqegC6M5ps50SJ9rCdpm1cMDGjfZ/crG5We+6GLT7Bov+ho17up/sFyneyyq0nHUACgMKZ93MhGvUPrW902eSTUr33T3ftsUdTCOTOU3r9Xx2t6MtzJ3bJfJ8gc3rFb6fzKKjOnvUMnxNQd0o8RL7aJXJUR/Z7bufsDpadOsec5XKd3tGnL8P6/en6g8KjDJp6dLryyE+IJNHZCPIHGTognZHcXVwcMjEiZTTnrdLl+XQjQ1t6pdH6e3RFmILCLa36J/Qxr79O+ZqgrN5pJ5hof/fLdow8aB/7tlxPzuB+7//tKT5s5X+lUhqKWwtm6OOb/vaR3ornqmhvMnFjAcrpbu5Q+1KfjAAAQi+tz10y1sYC9R7RfP7lU5wmcSRNUXtkJ8QQaOyGeQGMnxBNo7IR4QnYDdHCqsKUrQ3FKSyAgV1qqdVGB3n0EAPICHUUlbIMYBREd2AtHdLDkrefeMXOu/fhyc4zkNnNjOnlqe6CLUUWl7W6z9j1d7OMGdZD4td+tMnOmV+mEn5mJEqWnZeiIs79RP25FosuMqZ6q19cbSLz558dtZPPI0eFCo//zo2+Y3x+DV3ZCPIHGTogn0NgJ8YQsJ9U4DAwOF0D0J23ziu6enoDWfn1rp/bhAaCiPKH0wKD12XsH9ON2NGh/KVpgky2CCQzcbST3ObBPN41Yfrku5KnvsAU3N6+4TOkjtbVKd7fb91NDl+50W1YUaHiRtHPKy4qULim2jSm6u/X7tK9Dv/9Lim0hWGpEB1rbDmMYvnsJ8QQaOyGeQGMnxBNo7IR4QpY71TgMDA4nCSQHbKeOgUA32e4e3XWmtc12FO3q0R1Ru/rtts7RpH5cCYnSLRm24gnCgF1ukakCbNFc3emlsFC/zrE+m+xS36wfZ89RHcQLReycSSU6UNbdr9/LkSIdjAOA3g4d1Et22fe/BKozCwLJXy0tupMQALR2DgebBwdP/D7mu5UQT6CxE+IJNHZCPCHrhTCpEX56d9L63z3duhAg2RtIqmnXfg8AtHfp5Jy8JrsbRzSsfaxIntaD3HPyvODKKxco3Z7U/nfNJBvPGXA6FaW+VXeGTSTs9ssD/dq37ujU52nI8B6simnfv7jAJsh0dGub6OrQb8x+2M7JTQ3DxT4DJ9k8lVd2QjyBxk6IJ9DYCfGE7PrsqRR6+4Z9jnC+9VnaAztgFLVpX6ik1DYfaG5rUjovf5IZEwk8bnmgyQF4z/y8IBXI3SiJ6fvdDe22kGrOLN0QpbNT+82/fX+zmZMo1O+XosJCpWNxGxuonqS7ye4/0GjG9ARiDNMmJ5RubNDNOACgnj47IWQkNHZCPIHGTogn0NgJ8YTsFsII4ELDCQwuZTvVdPXoAEpXV0B32o60vb06+NbWYbeIKgskRgzq+gi1lTQ5dwm5QLFS4IWuLrEdiXY36jmx0oTSNy1daubkx3VAbrBXv0+TPTb5ZXAguN11jxlTntCB46MNOohX16iD0QDQ3jZ87sEMXZqOwSs7IZ5AYyfEE2jshHiCOHeyfpTjfDKRBgD7AUwCYDMKcpNzaa3AubXec2mtwLmx3pnOucpMv8iqsR8/qcga59yyrJ/4NDiX1gqcW+s9l9YKnHvrDcKv8YR4Ao2dEE84W8b+xFk67+lwLq0VOLfWey6tFTj31qs4Kz47IST78Gs8IZ6QVWMXkTtEZIeI7BaRx7J57rEgIj8WkXoR2TziWLmIvCwiu9L/l53sMbKFiEwXkVUislVEtojII+njubreqIi8KyLvp9f7zfTx2SKyOv2e+KmI2CbtZwkRCYvIehF5Ma1zdq1jIWvGLiJhAH8P4MMAFgN4QEQWn3xW1vkJgDsCxx4D8Kpzbh6AV9M6FxgA8EXn3GIAywF8Pv185up6ewHc7Jy7BMBSAHeIyHIAfwXg2865uQBaADx09pZoeATAthE6l9c6Ktm8sl8JYLdzbo9zrg/AMwDuyeL5R8U59waA4JYb9wBYmf55JYB7s7mmE+Gcq3XOrUv/3IGhN+VU5O56nXPuWMVGfvqfA3AzgJ+lj+fMekVkGoCPAPhRWgtydK1jJZvGPhXAwRH6UPpYrlPtnDu2YfdRANUnG3w2EJFZAC4FsBo5vN701+INAOoBvAzgAwCtzrljvZRy6T3xHQBfBo5vfl6B3F3rmGCA7hRwQ7cucur2hYjEAPwcwBecc6qpfq6t1zk36JxbCmAahr7pLTy7K8qMiNwFoN45t/Zsr2U8yWY9+2EA00foaeljuU6diNQ452pFpAZDV6WcQETyMWToTznn/jV9OGfXewznXKuIrAJwNYCEiOSlr5i58p5YAeBuEbkTQBRAHMDfIjfXOmayeWV/D8C8dEQzAuB+AC9k8fynywsAHkz//CCA58/iWo6T9iGfBLDNOff4iF/l6norRSSR/rkQwK0YijOsAnBfelhOrNc59xXn3DTn3CwMvU9fc859Cjm41lPCOZe1fwDuBLATQ77a17J57jGu72kAtQD6MeSTPYQhX+1VALsAvAKg/GyvM73WazH0FX0jgA3pf3fm8HovBrA+vd7NAL6ePn4BgHcB7AbwHICCs73WwLpvBPDiubDW0f4xg44QT2CAjhBPoLET4gk0dkI8gcZOiCfQ2AnxBBo7IZ5AYyfEE2jshHjC/wekEXYU0Z3c3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_0[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05a9040820>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_treino_cod[0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rede primaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_i, cnn_j, cnn_chnls = 50, 50, 3\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(50, (3, 3), input_shape = (cnn_i, cnn_j, cnn_chnls), activation = 'relu'))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(MaxPool2D((2, 2)))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(AvgPool2D((2, 2)))\n",
    "cnn.add(Conv2D(50, (3, 3), activation = 'relu'))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(AvgPool2D((2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Dense(25, activation = 'relu', kernel_regularizer = l2(0.05)))\n",
    "cnn.add(Dense(1, activation = 'relu'))\n",
    "        \n",
    "cnn.compile(loss = 'binary_crossentropy', optimizer = RMSprop(learning_rate = 0.001))\n",
    "\n",
    "es = EarlyStopping(monitor = 'loss', patience = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede com o encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 7s 350ms/step - loss: 9.3587 - val_loss: 6.7322\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 8.2067 - val_loss: 6.2904\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 8.0985 - val_loss: 6.2674\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 7.2716 - val_loss: 5.3171\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 6.5285 - val_loss: 5.2962\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 6.1434 - val_loss: 4.9205\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 6.1321 - val_loss: 4.8056\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 5.4053 - val_loss: 4.4572\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 5.1415 - val_loss: 4.2280\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 4.6762 - val_loss: 4.1280\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 4.4417 - val_loss: 3.8274\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 4.3048 - val_loss: 3.6114\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.9675 - val_loss: 3.4785\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.7600 - val_loss: 3.3644\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.5998 - val_loss: 3.1659\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.3232 - val_loss: 3.0203\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.1394 - val_loss: 2.7986\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 3.0640 - val_loss: 2.6204\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.7780 - val_loss: 2.5002\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 2.5050 - val_loss: 2.3739\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.4698 - val_loss: 2.2247\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 2.2936 - val_loss: 2.0711\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.0997 - val_loss: 2.0188\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 2.0529 - val_loss: 1.8306\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.8151 - val_loss: 1.7654\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.8014 - val_loss: 1.6757\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.6706 - val_loss: 1.6882\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.6010 - val_loss: 1.5723\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.5084 - val_loss: 1.4818\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 1.4278 - val_loss: 1.4024\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.3688 - val_loss: 1.3344\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.2608 - val_loss: 1.2523\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.2019 - val_loss: 1.1881\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 1.1260 - val_loss: 1.1244\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 1.1106 - val_loss: 1.0633\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 1.0529 - val_loss: 1.0441\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.9581 - val_loss: 0.9956\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.9392 - val_loss: 0.9557\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.9606 - val_loss: 0.9343\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.9091 - val_loss: 0.8981\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.8770 - val_loss: 0.8616\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.8067 - val_loss: 0.8371\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.8065 - val_loss: 0.8062\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7927 - val_loss: 0.7964\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7695 - val_loss: 0.7883\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7536 - val_loss: 0.7833\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7711 - val_loss: 0.7806\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7617 - val_loss: 0.7714\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7182 - val_loss: 0.7676\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7160 - val_loss: 0.7627\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7952 - val_loss: 0.7502\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7463 - val_loss: 0.7519\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6927 - val_loss: 0.7508\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7214 - val_loss: 0.7532\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7084 - val_loss: 0.7479\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6916 - val_loss: 0.7438\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.7004 - val_loss: 0.7430\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7700 - val_loss: 0.7437\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6982 - val_loss: 0.7250\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7311 - val_loss: 0.7456\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6906 - val_loss: 0.7416\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6731 - val_loss: 0.7293\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7034 - val_loss: 0.7258\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6938 - val_loss: 0.7197\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.7033 - val_loss: 0.7178\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6723 - val_loss: 0.7451\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6904 - val_loss: 0.7414\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6999 - val_loss: 0.7180\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6729 - val_loss: 0.7278\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6862 - val_loss: 0.7187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05a6aaf9a0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "cnn.fit(x_treino_cod, y_0, \n",
    "             epochs = 100,\n",
    "             validation_data = (x_valid_cod, y_valid),\n",
    "             callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_pred = cnn.predict(x_treino_cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938337624612135"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_0, y_treino_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede sem o encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 24ms/step - loss: 0.6763 - val_loss: 7.6455\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6889 - val_loss: 7.6445\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6808 - val_loss: 7.6442\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6585 - val_loss: 7.6457\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6914 - val_loss: 7.6461\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6539 - val_loss: 7.5099\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6626 - val_loss: 7.7059\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6484 - val_loss: 7.1244\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6342 - val_loss: 6.6903\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6052 - val_loss: 7.3482\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6034 - val_loss: 7.1634\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5916 - val_loss: 7.2306\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6297 - val_loss: 7.1708\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6067 - val_loss: 5.6251\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.5862 - val_loss: 7.2412\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6022 - val_loss: 5.2059\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.6077 - val_loss: 5.4841\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.5708 - val_loss: 7.2281\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.6266 - val_loss: 5.3958\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.5603 - val_loss: 7.6576\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.5403 - val_loss: 7.2528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05a8d7aac0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights = True)\n",
    "\n",
    "cnn.fit(x_0, y_0, \n",
    "             epochs = 100,\n",
    "             validation_data = (x_valid, y_valid),\n",
    "             callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_pred = cnn.predict(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8446116942848968"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_0, y_treino_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
