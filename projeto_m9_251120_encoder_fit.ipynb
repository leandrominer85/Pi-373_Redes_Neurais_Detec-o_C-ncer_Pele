{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score , roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, Input\n",
    "from tensorflow.keras.layers import Flatten, MaxPool2D, AvgPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Reshape, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ao carregarmos cada um dos batches, pré processaremos e faremos 'data augmentation', através de:\n",
    "\n",
    "# carregamento \n",
    "def get_images_n_labels(dataframe, path = 'treino_full_non_preproc/', \n",
    "                        series_name = 'img', label_name = 'pos', i = 300, j = 300):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for n in range(dataframe.shape[0]):\n",
    "        \n",
    "        img = cv2.imread(path + dataframe[series_name].iloc[n])\n",
    "        img = cv2.resize(img, (i, j))\n",
    "        x.append(img)\n",
    "        y.append(dataframe[label_name].iloc[n])\n",
    "        \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# pré processamento\n",
    "\n",
    "def segmentation(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations = 3)\n",
    "    res = cv2.bitwise_and(img,img,mask = sure_bg)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def bgr_CLAHE(img):\n",
    "    \n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    lab_planes = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit = 2.0,tileGridSize = (6, 6))\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "    lab = cv2.merge(lab_planes)\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def img_preproc(img):\n",
    "    \n",
    "    img = bgr_CLAHE(segmentation(img))\n",
    "    img = img / 255\n",
    "\n",
    "    \n",
    "    return img\n",
    "\n",
    "# augmentation\n",
    "\n",
    "def zoom(img, original_dim = [300, 300], h_slice = [25, 275], v_slice = [25, 275]):\n",
    "\n",
    "    img = img[v_slice[0] : v_slice[1], h_slice[0] : h_slice[1]]\n",
    "    img = cv2.resize(img, (original_dim[0], original_dim[1]))\n",
    "    \n",
    "    return img \n",
    "\n",
    "# horizontal shift\n",
    "def h_shift(image, original_dim = [300, 300], shift = 5):\n",
    "    \n",
    "    T_x = shift\n",
    "    T_y = 0\n",
    "    \n",
    "    M = np.array([[1, 0, T_x], [0, 1, T_y]], dtype = 'float32')\n",
    "    img_transladada = cv2.warpAffine(image, M, (original_dim[0], original_dim[1]))\n",
    "    img = img_transladada[0 : original_dim[0], shift : original_dim[1]]\n",
    "    img = cv2.resize(img, (original_dim[0], original_dim[1]))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# vertical shift\n",
    "def v_shift(image, original_dim = [300, 300], shift = 5):\n",
    "    \n",
    "    T_x = 0\n",
    "    T_y = shift\n",
    "    \n",
    "    M = np.array([[1, 0, T_x], [0, 1, T_y]], dtype = 'float32')\n",
    "    img_transladada = cv2.warpAffine(image, M, (original_dim[0], original_dim[1]))\n",
    "    img = img_transladada[shift : original_dim[0], 0 : original_dim[1]]\n",
    "    img = cv2.resize(img, (original_dim[0], original_dim[1]))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def rotation_90(img):\n",
    "\n",
    "    rows, cols, chnls = img.shape\n",
    "    M = cv2.getRotationMatrix2D(((cols - 1) / 2.0, (rows - 1) / 2.0), 90, 1)\n",
    "    img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def data_augmentation(x, y):\n",
    "    \n",
    "    augmentation_imgs = []\n",
    "    augmentation_labels = []\n",
    "\n",
    "    for n in range(len(x)):\n",
    "\n",
    "        image = x[n]\n",
    "        classe = y[n]\n",
    "        augment = randint(0, 2) # booleano (33.3% de chance de aplicar augmentation)\n",
    "\n",
    "        if augment == 1:\n",
    "            process = randint(0, 5) # seleção aleatória do processo de augmentation\n",
    "\n",
    "            if process == 0:\n",
    "                image = cv2.flip(image, 0)\n",
    "                augmentation_imgs.append(image) # horizontal flip\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 1:\n",
    "                image = zoom(image)\n",
    "                augmentation_imgs.append(image) # zoom 0.2\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 2:\n",
    "                image = h_shift(image)\n",
    "                augmentation_imgs.append(image) # horizontal shift\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 3:\n",
    "                image = v_shift(image)\n",
    "                augmentation_imgs.append(image) # vertical shift\n",
    "                augmentation_labels.append(classe)\n",
    "\n",
    "            if process == 4:\n",
    "                image = rotation_90(image)\n",
    "                augmentation_imgs.append(image) # rotaton 90°\n",
    "                augmentation_labels.append(classe)\n",
    "                \n",
    "    return augmentation_imgs, augmentation_labels\n",
    "\n",
    "# consolidando os processos acima em um função\n",
    "def single_batch_prep(batch_df, width = 300, height = 300):\n",
    "    \n",
    "    x, y = get_images_n_labels(batch_df)\n",
    "\n",
    "    # pré processamento de imagens\n",
    "    x = [img_preproc(i) for i in x]\n",
    "\n",
    "    # data augmentation\n",
    "    augmentation_imgs, augmentation_labels = data_augmentation(x, y)\n",
    "    \n",
    "    return np.array(x + augmentation_imgs), np.array(list(y) + augmentation_labels)\n",
    "\n",
    "\n",
    "def get_batch(nn_name, batch_desc, valid_desc, valid_dir, batch_size, epochs, \n",
    "              encode = False):\n",
    "    \n",
    "    model = load_model(nn_name)\n",
    "    batch = pickle.load(open(batch_desc, 'rb'))\n",
    "    x_treino, y_treino = single_batch_prep(batch)\n",
    "    \n",
    "    valid = pickle.load(open(valid_desc, 'rb'))\n",
    "    x_valid, y_valid = get_images_n_labels(valid, path = valid_dir)\n",
    "    \n",
    "    if encode == True:\n",
    "        model.fit(x_treino, x_treino, batch_size = batch_size, epochs = epochs, \n",
    "                  validation_data = (x_valid, x_valid))\n",
    "                  \n",
    "    model.save(nn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_h, px_v, chnls = 300, 300, 3\n",
    "ipt_e = Input(shape = (px_h, px_v, chnls))\n",
    "\n",
    "encoder = Conv2D(50, (3, 3), input_shape = (px_h, px_v, chnls), activation = 'relu', padding = 'same')(ipt_e)\n",
    "encoder = MaxPool2D((5, 5))(encoder)\n",
    "encoder = Conv2D(50, (5, 5), activation = 'relu', padding = 'same')(encoder)\n",
    "encoder = MaxPool2D((5, 5))(encoder)\n",
    "encoder = Conv2D(50, (5, 5), activation = 'relu', padding = 'same')(encoder)\n",
    "encoder = Flatten()(encoder)\n",
    "\n",
    "encoder = Dense(60, name = 'gargalo')(encoder)\n",
    "\n",
    "decoder = Dense(7200)(encoder)\n",
    "decoder = Reshape(target_shape = (12, 12,50))(decoder)\n",
    "decoder = Conv2D(50, (3, 3), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = UpSampling2D((5, 5))(decoder)\n",
    "decoder = Conv2D(50, (5, 5), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = UpSampling2D((5, 5))(decoder)\n",
    "decoder = Conv2D(4, (3, 3), activation = 'relu', padding = 'same')(decoder)\n",
    "decoder = Conv2D(3, (3, 3), activation = 'sigmoid', padding = 'same')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs = ipt_e, outputs = decoder, name = 'autoencoder')\n",
    "autoencoder.compile(loss = 'mean_squared_error')\n",
    "\n",
    "autoencoder.save('ae.h5') # <- atenção: não rodar esta linha várias vezes, rodar apenas ao criar o encoder,\n",
    "                          #    rodar esta linha sobrescreverá o encoder já treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-99ib2vsi/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7586d9e197ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ae.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_0.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df_valid.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'isic_2017_validacao/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c9828f38380c>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(nn_name, batch_desc, valid_desc, valid_dir, batch_size, epochs, encode)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mx_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_batch_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c9828f38380c>\u001b[0m in \u001b[0;36msingle_batch_prep\u001b[0;34m(batch_df, width, height)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msingle_batch_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images_n_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# pré processamento de imagens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c9828f38380c>\u001b[0m in \u001b[0;36mget_images_n_labels\u001b[0;34m(dataframe, path, series_name, label_name, i, j)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseries_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-99ib2vsi/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "get_batch('ae.h5', 'batch_0.pkl', 'df_valid.pkl', 'isic_2017_validacao/', 25, 100, encode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch('ae.h5', 'batch_1.pkl', 'df_valid.pkl', 'isic_2017_validacao/', 25, 100, encode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch('ae.h5', 'batch_2.pkl', 'df_valid.pkl', 'isic_2017_validacao/', 25, 100, encode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch('ae.h5', 'batch_3.pkl', 'df_valid.pkl', 'isic_2017_validacao/', 25, 100, encode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch('ae.h5', 'batch_4.pkl', 'df_valid.pkl', 'isic_2017_validacao/', 25, 100, encode = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
